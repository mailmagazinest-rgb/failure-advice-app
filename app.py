# app.py
import streamlit as st
import os
import csv
from io import BytesIO
import pandas as pd
import pdfplumber
from docx import Document
from datetime import datetime

from gpt_advice import query_gpt
from main import load_all_records, search_similar_records

st.set_page_config(page_title="å¤±æ•—äº‹ä¾‹ã‚¢ãƒ‰ãƒã‚¤ã‚¹Bot", layout="wide")
st.title("ğŸ› ï¸ å¤±æ•—äº‹ä¾‹ã‚¢ãƒ‰ãƒã‚¤ã‚¹Bot")

# ğŸ“¤ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆCSV, PDF, Excel, Wordå¯¾å¿œï¼‰
st.sidebar.header("ğŸ“¤ å¤±æ•—äº‹ä¾‹ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
uploaded_files = st.sidebar.file_uploader(
    "CSV, Excel, PDF, Word ã«å¯¾å¿œã—ã¦ã„ã¾ã™", 
    type=["csv", "xlsx", "pdf", "docx"], 
    accept_multiple_files=True
)

def extract_text_records_from_upload(file):
    ext = os.path.splitext(file.name)[1].lower()

    if ext == ".csv":
        df = pd.read_csv(file)
        return [(str(row.get("ã‚¿ã‚¤ãƒˆãƒ«", "ã‚¿ã‚¤ãƒˆãƒ«ãªã—")), str(row.get("æœ¬æ–‡", "æœ¬æ–‡ãªã—"))) for _, row in df.iterrows()]

    elif ext == ".xlsx":
        df = pd.read_excel(file, header=1)
        return [(str(row.get("ã‚¿ã‚¤ãƒˆãƒ«", "ã‚¿ã‚¤ãƒˆãƒ«ãªã—")), str(row.get("æœ¬æ–‡", "æœ¬æ–‡ãªã—"))) for _, row in df.iterrows()]

    elif ext == ".pdf":
        records = []
        with pdfplumber.open(BytesIO(file.read())) as pdf:
            for i, page in enumerate(pdf.pages):
                text = page.extract_text()
                if text:
                    records.append((f"{file.name} ãƒšãƒ¼ã‚¸{i+1}", text.strip()))
        return records

    elif ext == ".docx":
        doc = Document(file)
        records = []
        current_title = ""
        for para in doc.paragraphs:
            if para.style.name.startswith("Heading"):
                current_title = para.text.strip()
            elif para.text.strip():
                records.append((current_title or "ã‚¿ã‚¤ãƒˆãƒ«ãªã—", para.text.strip()))
        return records

    else:
        return []

# äº‹å‰ç™»éŒ²æ¸ˆã¿ï¼‹ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆä½“
@st.cache_resource
def load_records():
    return load_all_records("data")

base_records = load_records()
uploaded_records = []
for file in uploaded_files:
    uploaded_records.extend(extract_text_records_from_upload(file))

records = uploaded_records + base_records
st.caption(f"ğŸ“Š ä½¿ç”¨ä¸­ã®äº‹ä¾‹æ•°ï¼š{len(records)} ä»¶")

# ğŸ’¬ ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
query = st.text_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼šãƒã‚¸ãŒç·©ã‚€åŸå› ã¯ï¼Ÿï¼‰")

# ã‚»ãƒƒã‚·ãƒ§ãƒ³å±¥æ­´ä¿æŒ
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

if query:
    # â‘  é¡ä¼¼äº‹ä¾‹æ¤œç´¢
    results = search_similar_records(query, records)
    similar_text = "\n".join([f"ã€{title}ã€‘\n{body}" for _, title, body in results])

    # â‘¡ GPTã‚¢ãƒ‰ãƒã‚¤ã‚¹ç”Ÿæˆ
    with st.spinner("GPTãŒè€ƒãˆä¸­ã§ã™..."):
        answer = query_gpt(query, similar_text)

    # â‘¢ ãƒ­ã‚°ä¿å­˜
    os.makedirs("logs", exist_ok=True)
    with open("logs/chat_log.csv", mode="a", encoding="utf-8", newline="") as f:
        writer = csv.writer(f)
        writer.writerow([datetime.now().isoformat(), query, answer])

    # â‘£ ã‚»ãƒƒã‚·ãƒ§ãƒ³å±¥æ­´ä¿å­˜
    st.session_state.chat_history.append((query, answer))

    # ğŸ” é¡ä¼¼äº‹ä¾‹è¡¨ç¤º
    st.subheader("ğŸ” é¡ä¼¼äº‹ä¾‹ï¼ˆä¸Šä½3ä»¶ï¼‰")
    for score, title, body in results:
        with st.expander(f"{title}ï¼ˆã‚¹ã‚³ã‚¢: {score:.2f}ï¼‰"):
            st.write(body)

    # ğŸ’¡ GPTã‚¢ãƒ‰ãƒã‚¤ã‚¹è¡¨ç¤º
    st.subheader("ğŸ’¡ GPTã«ã‚ˆã‚‹ã‚¢ãƒ‰ãƒã‚¤ã‚¹")
    st.success(answer)

    # ğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ï¼ˆå…¨æ–‡ï¼‰
    download_text = ""
    for score, title, body in results:
        download_text += f"ã€{title}ã€‘ï¼ˆã‚¹ã‚³ã‚¢: {score:.2f}ï¼‰\n{body}\n\n"

    st.download_button(
        label="ğŸ“¥ é¡ä¼¼äº‹ä¾‹ã‚’ãƒ†ã‚­ã‚¹ãƒˆã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=download_text,
        file_name="similar_cases.txt",
        mime="text/plain"
    )

# ğŸ“– ã‚»ãƒƒã‚·ãƒ§ãƒ³å†…å±¥æ­´è¡¨ç¤º
if st.session_state.chat_history:
    with st.expander("ğŸ“– ã“ã‚Œã¾ã§ã®ã‚„ã‚Šå–ã‚Šï¼ˆã“ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ï¼‰"):
        for i, (q, a) in enumerate(reversed(st.session_state.chat_history), 1):
            st.markdown(f"**Q{i}ï¼š{q}**")
            st.markdown(f"ğŸ§  A{i}ï¼š{a}")
