import os
import pandas as pd
import pdfplumber

# CSVèª­ã¿è¾¼ã¿
def load_csv(filepath):
    df = pd.read_csv(filepath)
    records = []
    for _, row in df.iterrows():
        title = str(row.get("ã‚¿ã‚¤ãƒˆãƒ«", "ã‚¿ã‚¤ãƒˆãƒ«ãªã—"))
        body = str(row.get("æœ¬æ–‡", "æœ¬æ–‡ãªã—"))
        records.append((title, body))
    return records

# Excelèª­ã¿è¾¼ã¿
def load_excel(filepath):
    df = pd.read_excel(filepath, header=1)
    records = []
    for _, row in df.iterrows():
        title = str(row.get("ã‚¿ã‚¤ãƒˆãƒ«", "ã‚¿ã‚¤ãƒˆãƒ«ãªã—"))
        body = str(row.get("æœ¬æ–‡", "æœ¬æ–‡ãªã—"))
        records.append((title, body))
    return records

# PDFèª­ã¿è¾¼ã¿ï¼ˆ1ãƒšãƒ¼ã‚¸1äº‹ä¾‹ã¨ã—ã¦æ‰±ã†ï¼‰
def load_pdf(filepath):
    records = []
    with pdfplumber.open(filepath) as pdf:
        for i, page in enumerate(pdf.pages):
            text = page.extract_text()
            if text:
                title = f"{os.path.basename(filepath)} ãƒšãƒ¼ã‚¸{i+1}"
                body = text.strip()
                records.append((title, body))
    return records

# æ‹¡å¼µå­ã”ã¨ã«åˆ†å²
def extract_text_records(file_path):
    ext = os.path.splitext(file_path)[1].lower()
    if ext == ".csv":
        return load_csv(file_path)
    elif ext == ".xlsx":
        return load_excel(file_path)
    elif ext == ".pdf":
        return load_pdf(file_path)
    else:
        return []  # æœªå¯¾å¿œã®æ‹¡å¼µå­ã¯ã‚¹ã‚­ãƒƒãƒ—

# ðŸ” è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ‹¬å‡¦ç†
def load_all_records(folder_path):
    all_records = []
    for file in os.listdir(folder_path):
        if file.lower().endswith(('.csv', '.xlsx', '.pdf')):
            full_path = os.path.join(folder_path, file)
            print(f"ðŸ“‚ å‡¦ç†ä¸­: {file}")
            try:
                records = extract_text_records(full_path)
                all_records.extend(records)
            except Exception as e:
                print(f"âŒ ã‚¨ãƒ©ãƒ¼: {file} - {e}")
    return all_records

# âœ… å®Ÿè¡Œéƒ¨
if __name__ == "__main__":
    folder = "data"
    records = load_all_records(folder)

    print(f"\nâœ… åˆè¨ˆèª­ã¿è¾¼ã¿ä»¶æ•°: {len(records)} ä»¶\n")
    for title, body in records[:3]:  # æœ€åˆã®3ä»¶ã ã‘è¡¨ç¤º
        print(f"ðŸ”¸ {title}\n{body[:100]}...\n")


import pdfplumber
import os
import pandas as pd

def extract_text_from_pdf(filepath):
    try:
        with pdfplumber.open(filepath) as pdf:
            texts = [page.extract_text() for page in pdf.pages if page.extract_text()]
        return "\n".join(texts)
    except Exception as e:
        return f"(PDFèª­è¾¼å¤±æ•—: {e})"

def extract_text_records(filepath):
    ext = os.path.splitext(filepath)[1].lower()

    if ext == '.csv':
        df = pd.read_csv(filepath)
    elif ext == '.xlsx':
        df = pd.read_excel(filepath)
    elif ext == '.pdf':
        text = extract_text_from_pdf(filepath)
        return [(os.path.basename(filepath), text)]
    else:
        return []

    records = []
    for _, row in df.iterrows():
        title = str(row[0]) if len(row) > 0 else ""
        body = str(row[1]) if len(row) > 1 else ""
        records.append((title, body))
    return records

def load_all_records(folder):
    all_records = []
    for file in os.listdir(folder):
        path = os.path.join(folder, file)
        if os.path.isfile(path):
            all_records.extend(extract_text_records(path))
    return all_records

from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity

model = SentenceTransformer("all-MiniLM-L6-v2")

def search_similar_records(query, records, top_k=3):
    texts = [title + " " + body for title, body in records]
    query_vec = model.encode([query])
    record_vecs = model.encode(texts)

    similarities = cosine_similarity(query_vec, record_vecs)[0]
    top_indices = similarities.argsort()[::-1][:top_k]

    results = []
    for idx in top_indices:
        score = similarities[idx]
        title, body = records[idx]
        results.append((score, title, body))
    return results


from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity

model = SentenceTransformer("all-MiniLM-L6-v2")

def search_similar_records(query, records, top_k=3):
    texts = [title + " " + body for title, body in records]
    query_vec = model.encode([query])
    record_vecs = model.encode(texts)

    similarities = cosine_similarity(query_vec, record_vecs)[0]
    top_indices = similarities.argsort()[::-1][:top_k]

    results = []
    for idx in top_indices:
        score = similarities[idx]
        title, body = records[idx]
        results.append((score, title, body))
    return results
